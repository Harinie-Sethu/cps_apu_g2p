{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fbe715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fbde83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define our common CPS phone set (lowercase)\n",
    "cps_set = {\n",
    "    'a', 'aa', 'i', 'ii', 'u', 'uu', 'e', 'ee',\n",
    "    'k', 'kh', 'g', 'gh', 'c', 'ch', 'j', 'jh',\n",
    "    'tx', 'txh', 'dx', 'dxh', 't', 'th', 'd', 'dh',\n",
    "    'p', 'ph', 'b', 'bh', 'm', 'y', 'r', 'l', 'w',\n",
    "    'sh', 's', 'h', 'kq', 'gq', 'z', 'jhq', 'dxq',\n",
    "    'dxhq', 'f', 'ss', 'dd', 'dh2', 'dz', 'ai', 'hh', 'awu'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e123e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load IPA → ARPAbet mapping (invert the ARPAbet→IPA map)\n",
    "ipa2arp = {}\n",
    "with open(\"tools/ipa_arpabet_map.txt\", encoding=\"utf-8\") as mfile:\n",
    "    for line in mfile:\n",
    "        line = line.strip()\n",
    "        if not line or \"\\t\" not in line:\n",
    "            continue\n",
    "        arpabet_sym, ipa_esc = line.split(\"\\t\", 1)\n",
    "        # Decode unicode escapes to get the actual IPA string\n",
    "        ipa_chars = ipa_esc.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "        # Optionally strip stress digits from ARPAbet symbol:\n",
    "        base_arp = re.sub(r\"\\d+$\", \"\", arpabet_sym)\n",
    "        # Map each IPA sequence to its base ARPAbet symbol\n",
    "        ipa2arp[ipa_chars] = base_arp\n",
    "\n",
    "def ipa_to_arp(tokens):\n",
    "    \"\"\"Convert list of IPA tokens to ARPAbet symbols via direct lookup.\"\"\"\n",
    "    return [ipa2arp.get(tok, \"UNK\") for tok in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9acf31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold-standard ARPAbet lexicons generated in data/gold/\n"
     ]
    }
   ],
   "source": [
    "# 2. Process raw broad IPA files for Arabic, Persian, Urdu\n",
    "lang_codes = {\"ara\": \"arabic\", \"fas\": \"persian\", \"urd\": \"urdu\"}\n",
    "os.makedirs(\"data/gold\", exist_ok=True)\n",
    "\n",
    "for code, lang in lang_codes.items():\n",
    "    in_path = f\"data/raw/{code}_arab_broad.tsv\"\n",
    "    out_path = f\"data/gold/{lang}_manual.tsv\"\n",
    "    \n",
    "    with open(in_path, encoding=\"utf-8\") as fin, open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, ipa_seq = line.split(\"\\t\", 1)\n",
    "            tokens = ipa_seq.split()\n",
    "            arpabets = ipa_to_arp(tokens)\n",
    "            fout.write(f\"{word}\\t{' '.join(arpabets)}\\n\")\n",
    "\n",
    "print(\"Gold-standard ARPAbet lexicons generated in data/gold/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae225cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[arabic] still unknown IPA tokens: ['i', 'x', 'ħ', 'ɑ', 'ɒ', 'ʔ', '‿']\n",
      "[arabic] ARPABET symbols outside CPS set: ['ae', 'ah', 'ax', 'eh', 'ey', 'ih', 'iy', 'n', 'ow', 'q', 'uh', 'unk', 'uw', 'v', 'zh']\n",
      "[persian] still unknown IPA tokens: [',', 'i', 'x', '~', 'ɒ', 'ɹ', 'ɾ', 'ʔ']\n",
      "[persian] ARPABET symbols outside CPS set: ['ae', 'ah', 'ao', 'eh', 'ey', 'ih', 'iy', 'n', 'ow', 'q', 'uh', 'unk', 'uw', 'v', 'zh']\n",
      "[urdu] still unknown IPA tokens: ['i', 'x', '~', 'ɑ', 'ɒ', 'ɡː', 'ɾ', 'ʔ', 'ʰ', 'ʱ', '◌̃']\n",
      "[urdu] ARPABET symbols outside CPS set: ['ae', 'ah', 'ao', 'ax', 'eh', 'ey', 'ih', 'iy', 'n', 'ng', 'ow', 'q', 'uh', 'unk', 'uw', 'v', 'zh']\n",
      "Mapping complete; gold lexicons in data/gold/\n"
     ]
    }
   ],
   "source": [
    "# 2. Load IPA → ARPAbet mapping (invert ARPAbet->IPA)\n",
    "ipa2arp = {}\n",
    "with open(\"tools/ipa_arpabet_map.txt\", encoding=\"utf-8\") as mfile:\n",
    "    for line in mfile:\n",
    "        line = line.strip()\n",
    "        if not line or \"\\t\" not in line:\n",
    "            continue\n",
    "        arpabet_sym, ipa_esc = line.split(\"\\t\", 1)\n",
    "        base_arp = re.sub(r\"\\d+$\", \"\", arpabet_sym).lower()\n",
    "        ipa_seq = ipa_esc.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "        ipa2arp[ipa_seq] = base_arp\n",
    "\n",
    "# 3. Extended fallback mapping for uncovered IPA symbols\n",
    "fallback_map = {\n",
    "    # Arabic extras\n",
    "    'a': 'aa', 'aː': 'aa', 'bː': 'b', 'dˤ': 'dh2', 'd̪ˤ': 'dh2',\n",
    "    'd͡ʒ': 'jh', 'e': 'eh', 'eː': 'ey', 'l': 'l', 'o': 'ow', 'oː': 'ow',\n",
    "    'q': 'q', 'r': 'r', 'sˤ': 'ss', 'tˀ': 't', 'tˤ': 't', 'uː': 'uw',\n",
    "    'æː': 'ae', 'ðˤ': 'dh2', 'ō': 'ow', 'ɐ': 'ax', 'ɣ': 'gq',\n",
    "    'ɮˤ': 'l', 'ʁ': 'r', 'ʕ': 'ai', 'χ': 'kh', '‿': '',\n",
    "\n",
    "    # Persian extras\n",
    "    ',': '', 'dː': 'd', 'd̪': 'd', 'i̯': 'y', 'kʰ': 'kh', 'kʲ': 'k',\n",
    "    'sː': 's', 'tʰ': 'th', 'tː': 't', 't̪': 't', 't͡ʃ': 'ch', 't͡ʃʰ': 'ch',\n",
    "    '~': '', 'ɒː': 'ao', 'ɔː': 'ao', 'ɡʱ': 'g', 'ɡʷ': 'g', 'ɢ': 'q',\n",
    "    'ɵ': 'uh', 'ʃʰ': 'sh', 'ʃː': 'sh', 'ʊ̯': 'w', 'β': 'b',\n",
    "\n",
    "    # Urdu extras\n",
    "    'bʱ': 'bh', 'bː': 'b', 'bᵊ': 'b', 'd̪ʱ': 'dh', 'd̪ː': 'd',\n",
    "    'd̪ːʰ': 'dh', 'd̪̪': 'd', 'd̪ᵊ': 'd', 'd͡z': 'z', 'd͡ʒʱ': 'jh',\n",
    "    'd͡ʒː': 'jh', 'd͡ʒᵊ': 'jh', 'eʱ': 'eh', 'jː': 'y', 'jᵊ': 'y',\n",
    "    'kː': 'k', 'lː': 'l', 'l̪': 'l', 'mʱ': 'm', 'mː': 'm', 'mᵊ': 'm',\n",
    "    'nʱ': 'n', 'nː': 'n', 'nᵊ': 'n', 'pʰ': 'ph', 'pː': 'p', 'qː': 'q',\n",
    "    'rː': 'r', 't̪ʰ': 'th', 't̪ː': 't', 't̪̤': 't', 't͡ʃʰᵊ': 'ch',\n",
    "    't͡ʃːʰ': 'ch', 'xʷ': 'kh', 'xː': 'kh', 'zː': 'z', 'z̥': 'z',\n",
    "    'ä': 'ae', 'õ': 'ow', 'õː': 'ow', 'ē': 'ey', 'ĩː': 'iy', 'ũː': 'uw',\n",
    "    'ɑ̃ː': 'aa', 'ɑ̃ːᵑ': 'aa', 'ɔ̃ː': 'ao', 'ə̃': 'ax', 'ə̯': 'ax',\n",
    "    'əᵊ': 'ax', 'ɛː': 'eh', 'ɛ̃ː': 'eh', 'ẽː': 'eh', '◌̃': '',\n",
    "    'ɖ': 'dx', 'ɖʱ': 'dxh', 'ɖː': 'dx', 'ɦ': 'h', 'ɪ̃': 'ih',\n",
    "    'ɪ̯': 'y', 'ɲ': 'n', 'ɳ': 'n', 'ɽ': 'r', 'ɽʱ': 'r', 'ɾᵊ': 'r',\n",
    "    'ʈ': 'tx', 'ʈʰ': 'txh', 'ʈʱ': 'txh', 'ʈː': 'tx', 'ʊ̃': 'uh',\n",
    "    'ʋ': 'v', 'ʋː': 'v', 'ʋᵊ': 'v'\n",
    "}\n",
    "\n",
    "# Merge fallback into ipa2arp (without overwriting existing)\n",
    "for ipa_seq, arp_sym in fallback_map.items():\n",
    "    ipa2arp.setdefault(ipa_seq, arp_sym)\n",
    "\n",
    "# 4. Conversion function\n",
    "def ipa_to_arpabets(tokens, unknowns):\n",
    "    arpabets = []\n",
    "    for tok in tokens:\n",
    "        arp = ipa2arp.get(tok)\n",
    "        if not arp:\n",
    "            unknowns.add(tok)\n",
    "            arp = 'unk'\n",
    "        arpabets.append(arp)\n",
    "    return arpabets\n",
    "\n",
    "# 5. Process files\n",
    "lang_codes = {'ara': 'arabic', 'fas': 'persian', 'urd': 'urdu'}\n",
    "os.makedirs(\"data/gold\", exist_ok=True)\n",
    "\n",
    "for code, lang in lang_codes.items():\n",
    "    in_path = f\"data/raw/{code}_arab_broad.tsv\"\n",
    "    out_path = f\"data/gold/{lang}_manual.tsv\"\n",
    "    unknowns = set()\n",
    "    \n",
    "    with open(in_path, encoding=\"utf-8\") as fin, open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            word, ipa_seq = line.strip().split(\"\\t\", 1)\n",
    "            tokens = ipa_seq.split()\n",
    "            arpabets = ipa_to_arpabets(tokens, unknowns)\n",
    "            fout.write(f\"{word}\\t{' '.join(arpabets)}\\n\")\n",
    "    \n",
    "    if unknowns:\n",
    "        print(f\"[{lang}] still unknown IPA tokens: {sorted(unknowns)}\")\n",
    "    # Check any ARPAbet not in CPS\n",
    "    unexpected = set()\n",
    "    with open(out_path) as fcheck:\n",
    "        for lw in fcheck:\n",
    "            _, seq = lw.strip().split(\"\\t\")\n",
    "            for arp in seq.split():\n",
    "                if arp not in cps_set:\n",
    "                    unexpected.add(arp)\n",
    "    if unexpected:\n",
    "        print(f\"[{lang}] ARPABET symbols outside CPS set: {sorted(unexpected)}\")\n",
    "\n",
    "print(\"Mapping complete; gold lexicons in data/gold/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
